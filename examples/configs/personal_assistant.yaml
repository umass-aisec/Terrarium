simulation:
  max_iterations: 1
  max_planning_rounds: 3
  max_conversation_steps: 3
  enable_agent_blackboard_actions: true
  n_simulations: 1
  parallelization:
    enabled: true
    max_workers: 1
  tag: baseline
environment:
  name: PersonalAssistant
  n_agents: 6
  max_degree: 3
  rng_seed: 42
  min_outfits_per_agent: 3
  max_outfits_per_agent: 4
  p_add_unary_color: 0.7
llm:
  # Provider: "openai", "anthropic", "gemini", or "vllm"
  provider: "openai"
  openai:
    model: "gpt-4.1-mini-2025-04-14"
  anthropic:
    model: "claude-3-5-sonnet-20241022"
  gemini:
    model: "gemini-2.0-flash-lite"
  # TODO: Get vLLM configuration working
  vllm:
    model_name: /data/huggingface/models--Qwen--Qwen3-235B-A22B-Thinking-2507/snapshots/d24ea3047182ca7b02f8b9f5d4e06f7be78c6885
    host: localhost
    port: 8000
    prefer_existing_server: true
    auto_start_server: true
    trust_remote_code: true
    connection_timeout: 30
    max_retries: 4
    max_model_len: 65536
    gpu_memory_utilization: 0.8
    tensor_parallel_size: 8
    additional_args: []
notes:
- PersonalAssistant baseline configuration (no attacks)
- Environment generates outfit coordination factors between agents
- Agents coordinate via blackboards during planning phase
- Final outfit selection happens during execution phase
- Simulation stops when all constraints satisfied or max iterations reached
- Generate n=30 instances and average results for evaluation
